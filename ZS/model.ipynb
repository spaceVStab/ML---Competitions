{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import math\n",
    "from __future__ import division\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "INPUT_DIR = \"dataset\"\n",
    "\n",
    "#os.listdir(INPUT_DIR)\n",
    "\n",
    "#os.chdir(INPUT_DIR)\n",
    "expense = pd.read_csv(\"promotional_expense.csv\")\n",
    "train = pd.read_csv(\"yds_train2018.csv\")\n",
    "test = pd.read_csv(\"yds_test2018.csv\")\n",
    "holiday = pd.read_excel(\"holidays.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "holiday['Date'] = holiday.Date.apply(lambda x: re.sub(r'\\s','',x))\n",
    "\n",
    "holiday.Date = pd.to_datetime(holiday.Date, format=\"%Y,%m,%d\")\n",
    "\n",
    "holiday[\"Year\"] = holiday.Date.apply(lambda x: x.year)\n",
    "holiday[\"Month\"] = holiday.Date.apply(lambda x: x.month)\n",
    "holiday[\"Day\"] = holiday.Date.apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_grouped = holiday.groupby(by = ['Year','Month','Country'], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_grouped = holiday_grouped.agg({\"Holiday\":\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "expense = expense.rename(columns = {\"Product_Type\":\"Product_ID\"})\n",
    "train = pd.merge(train, expense, how='left', on= ['Year','Month','Country','Product_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = train.groupby(by=['Year','Month','Country','Product_ID'], as_index=False)\n",
    "train_grouped = train_grouped.agg({\"Sales\":\"sum\", \"Expense_Price\":\"mean\"})\n",
    "\n",
    "test = pd.merge(test, expense, how=\"left\", on=['Year','Month','Country','Product_ID'])\n",
    "test_grouped = test.groupby(by=['Year','Month','Country','Product_ID'], as_index=False)\n",
    "test_grouped = test_grouped.agg({\"Sales\":\"sum\",\"Expense_Price\":\"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_grouped['Expense_Price'] = train_grouped['Expense_Price'].fillna(train_grouped['Expense_Price'].mean())\n",
    "# test_grouped['Expense_Price'] = test_grouped['Expense_Price'].fillna(test_grouped['Expense_Price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = pd.merge(train_grouped, holiday_grouped, how='left', on=['Year','Month','Country'])\n",
    "test_grouped = pd.merge(test_grouped, holiday_grouped, how='left', on=['Year','Month','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3 = train_grouped[train_grouped['Product_ID'] == 3]\n",
    "train_not3 = train_grouped[train_grouped['Product_ID'] != 3]\n",
    "test_3 = test_grouped[test_grouped['Product_ID'] == 3]\n",
    "test_not3 = test_grouped[test_grouped['Product_ID'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_not3['Holiday'] = train_not3['Holiday'].fillna(0)\n",
    "test_not3['Holiday'] = test_not3['Holiday'].fillna(0)\n",
    "train_3['Holiday'] = train_3['Holiday'].fillna(0)\n",
    "test_3['Holiday'] = test_3['Holiday'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_en = LabelEncoder()\n",
    "label_en.fit(list(train_grouped['Country'].values)+list(test_grouped['Country'].values))\n",
    "train_grouped['Country'] = label_en.transform(list(train_grouped['Country'].values))\n",
    "test_grouped['Country'] = label_en.transform(list(test_grouped['Country'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped['Holiday'] = train_grouped['Holiday'].fillna(0)\n",
    "test_grouped['Holiday'] = test_grouped['Holiday'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 0]\n",
      "2\n",
      "\n",
      "(12, 6)\n",
      "0\n",
      "\n",
      "(12, 6)\n",
      "2\n",
      "[3, 2, 1, 0]\n",
      "3\n",
      "\n",
      "(12, 6)\n",
      "2\n",
      "\n",
      "(12, 6)\n",
      "1\n",
      "\n",
      "(12, 6)\n",
      "0\n",
      "\n",
      "(12, 6)\n",
      "4\n",
      "[5, 4]\n",
      "5\n",
      "\n",
      "(9, 6)\n",
      "4\n",
      "\n",
      "(9, 6)\n",
      "5\n",
      "[4]\n",
      "4\n",
      "\n",
      "(9, 5)\n",
      "3\n",
      "[2, 0]\n",
      "2\n",
      "\n",
      "(3, 5)\n",
      "0\n",
      "\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "IDS = [1,2,4,5,3]\n",
    "features = ['Year','Month','Country','Product_ID','Expense_Price','Holiday']\n",
    "target = 'Sales'\n",
    "predict = pd.DataFrame(columns=['Year','Month','Country','Product_ID','Expense_Price','Holiday','Sales'])\n",
    "\n",
    "for i in IDS:\n",
    "    features = ['Year','Month','Country','Product_ID','Expense_Price','Holiday']\n",
    "    uni_country = list(train_grouped[train_grouped['Product_ID'] == i]['Country'].value_counts().index)\n",
    "    print(i)\n",
    "    print(uni_country)\n",
    "    if i == 3:\n",
    "        features.remove('Expense_Price')\n",
    "    else:\n",
    "        pass\n",
    "    if(len(uni_country) == 1):\n",
    "        features.remove('Country')\n",
    "    else:\n",
    "        pass\n",
    "    for c in uni_country:\n",
    "        print(c)\n",
    "        train_temp = train_grouped.loc[train_grouped['Product_ID'] == i].loc[train_grouped['Country'] == c]\n",
    "        test_temp = test_grouped.loc[test_grouped['Product_ID'] == i].loc[test_grouped['Country'] == c]\n",
    "        print()\n",
    "    #     salesScaler = MinMaxScaler().fit(train_temp[['Sales']])\n",
    "    #     train_temp.loc[:,['Sales']] = salesScaler.transform(train_temp[['Sales']])\n",
    "\n",
    "    #     expenseScaler = MinMaxScaler().fit(list(train_not3['Expense_Price'].values)+list(test_not3['Expense_Price'].values))\n",
    "    #     train_not3.loc[:,['Expense_Price']] = expenseScaler.transform(train_not3[['Expense_Price']])\n",
    "    #     test_temp.loc[:,['Expense_Price']] = expenseScaler.transform(test_temp[['Expense_Price']])\n",
    "        \n",
    "        train_X = train_temp[features]\n",
    "        train_y = train_temp[target].values\n",
    "        test_X = test_temp[features]\n",
    "        test_y = test_temp[target].values\n",
    "        print(test_X.shape)\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mape',\n",
    "            'min_data_in_leaf': 2,\n",
    "            'learning_rate': .1,\n",
    "            'num_leaves': 16,\n",
    "            'max_depth': 0,\n",
    "        }\n",
    "        lgb_train = lgb.Dataset(train_X,train_y)\n",
    "        gbm = lgb.train(params, lgb_train, num_boost_round=20)\n",
    "        test_y_gbm = gbm.predict(test_X)\n",
    "        \n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(train_X.values, train_y)\n",
    "        test_y_lin = regr.predict(test_X.values)\n",
    "        \n",
    "        lasso = linear_model.Lasso()\n",
    "        lasso.fit(train_X.values, train_y)\n",
    "        test_y_lasso = lasso.predict(test_X.values)\n",
    "        \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(train_X.values, train_y)\n",
    "        test_y_rf = rf.predict(test_X.values)\n",
    "        \n",
    "        xgb = xgboost.XGBRegressor()\n",
    "        xgb.fit(train_X.values, train_y)\n",
    "        test_y_xgb = xgb.predict(test_X.values)\n",
    "        \n",
    "        test_y = 0.5*test_y_xgb + 0.5*test_y_lasso\n",
    "        test_temp['Sales'] = list(test_y)\n",
    "        predict = pd.concat([predict,test_temp],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 7)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predict['Country'] = label_en.inverse_transform(list(predict['Country'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict['Year'] = predict['Year'].astype('str').astype('int')\n",
    "predict['Month'] = predict['Month'].astype('str').astype('int')\n",
    "predict['Product_ID'] = predict['Product_ID'].astype('str').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.merge(test, predict, how='inner', on=['Year','Month','Country','Product_ID'])\n",
    "predict = predict[['S_No','Year','Month','Product_ID','Country','Sales_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.rename(columns={\"Sales_y\":\"Sales\"})\n",
    "predict.to_csv(\"subs8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
